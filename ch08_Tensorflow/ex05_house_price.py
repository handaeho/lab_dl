# -*- coding: utf-8 -*-
"""House_Price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JB3hRwCFsfr0N7ArBnmD_MrwIW1ai_-m

# housing.csv파일로 Boston House Price 예측하기
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

"""**업로드한 housing.csv 파일을 읽고 데이터 프레임 생성**"""

import pandas as pd

df = pd.read_csv('data/housing.csv', header=None, delim_whitespace=True)
# ~> header=None: csv 파일에 컬럼 이름들이 없기 때문
# ~> delim_whitespace=True: csv 파일의 데이터가 공백으로 구분되고 있기 때문
df.head()
# print(df.shape)

"""**DataFrame을 데이터(집값에 영향을 미치는 변수들)과 집값을 분리**"""

dataset = df.to_numpy()
X = dataset[:, :-1]
Y = dataset[:, -1]
print(f'X shape: {X.shape}, Y shape: {Y.shape}')

"""**X, Y를 train_set / test_set으로 분할**"""

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)
print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')
print(f'Y_train shape: {Y_train.shape}, Y_test shape: {Y_test.shape}')

"""**신경망 생성**"""

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()

# Fully-connected layer 추가 - hidden_layer 2개, output_layer
model.add(Dense(30, activation='relu', input_dim=13)) # ~> 1st_hidden_layer
# input_dim=X_trian.shape[1]

model.add(Dense(6, activation='relu')) # ~> 2nd_hidden_layer

model.add(Dense(1)) # ~> output_layer
# 활성화 함수는 '예측 집값'이라는 output이 1개여서 없어도 된다. 

# 모델 컴파일
model.compile(loss='mean_squared_error', # 분류가 아닌 수치 예측이므로 MSE
              optimizer='adam')

"""**모델 학습(fit)**"""

history = model.fit(X_train, Y_train, batch_size=10, epochs=200,
                    validation_split=0.2)

"""**모델 평가 - 학습시킨 모델에 테스트 데이터로 평가**"""

eval = model.evaluate(X_test, Y_test)
print(eval)

"""**주택 가격의 예측값 확인**"""

y_pred = model.predict(X_test) # y_pred는 2차원 배열
y_pred = y_pred.flatten() # 2차원 배열 y_pred를 1차원 배열로

# 실제값과 예측값 비교(10개만)
for i in range(10):
  true_val = Y_test[i]
  pred_val = y_pred[i]
  squared_error = (true_val - pred_val) ** 2
  print(f'true: {true_val}, pred: {pred_val}, se: {squared_error}')

# Epochs-MSE 그래프
import matplotlib.pyplot as plt

losses = history.history['loss']
val_losses = history.history['val_loss']

plt.plot(losses, label='Train MSE')
plt.plot(val_losses, label='Test MSE')
plt.legend()
plt.show()

"""**모델 성능 개선 및 재 평가**"""

# X_train ~~~> Z-Score로 변환(z = (x - mean) / std)) 
# X_test 데이터는 X_train의 평균과 표준편차를 사용해 변환하고 평가 / 예측에 사용
import numpy as np

train_data = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)
test_data = (X_test - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)
print('X_train_z_score =', train_data)
print('X_test_z_score =', test_data)

# 변환된 데이터를 학습 시킬 모델 생성

# Fully-connected layer 추가 - hidden_layer 2개, output_layer
model.add(Dense(30, activation='relu', input_dim=13)) # ~> 1st_hidden_layer
# input_dim=X_trian.shape[1]

model.add(Dense(6, activation='relu')) # ~> 2nd_hidden_layer

model.add(Dense(1)) # ~> output_layer
# 활성화 함수는 '예측 집값'이라는 output이 1개여서 없어도 된다. 

# 모델 컴파일
model.compile(loss='mean_squared_error', # 분류가 아닌 수치 예측이므로 MSE
              optimizer='adam')

# Z-Score로 변환된 X_train_z_score / X_test_z_score로 다시 학습
history = model.fit(train_data, Y_train, batch_size=10, epochs=200,
                    validation_split=0.2)

# 재 학습된 모델을 재 평가
eval = model.evaluate(test_data, Y_test)
print(eval)

y_pred = model.predict(test_data) # y_pred는 2차원 배열
y_pred = y_pred.flatten() # 2차원 배열 y_pred를 1차원 배열로

# 실제값과 예측값 비교(10개만)
for i in range(10):
  true_val = Y_test[i]
  pred_val = y_pred[i]
  squared_error = (true_val - pred_val) ** 2
  print(f'true: {true_val}, pred: {pred_val}, se: {squared_error}')

# 개선된 모델의 Epochs-MSE 그래프
import matplotlib.pyplot as plt

losses = history.history['loss']
val_losses = history.history['val_loss']

plt.plot(losses, label='Train MSE')
plt.plot(val_losses, label='Test MSE')
plt.legend()
plt.show()

"""**K-Fold 교차 검증 <br/>**
k-Fold Cross Validation은 Train Dataset을 균등하게 k개의 그룹(Fold)으로 나누고 (k - 1)개의 Test Fold와 1개의 Validation Fold로 지정.<br/>  그리고 나서 총 k회 검증을 하는데, 각 검증마다 Test Fold를 다르게 지정하여 성능을 측정. <br/>
이런 식으로 k회 검증이 완료되면 
각 Hyperparameter에 대한 검증 결과를 평균을 내어 Hyperparameters를 튜닝한다.
"""

# K-Fold 모델 생성
def build_model():
    model = Sequential()
    # fully-connected layer를 추가 - 은닉층 2개, 출력층
    model.add(Dense(30, activation='relu', 
                    input_dim=X_train.shape[1]))  # 은닉층
    model.add(Dense(6, activation='relu'))  # 은닉층
    model.add(Dense(1))  # 출력층
    # 모델 컴파일
    model.compile(loss='mean_squared_error',  # 회귀(regression) - 수치 예측
                optimizer='adam')
    return model

k = 4  # k-fold cross-validation
num_val_samples = len(train_data) // k
num_epochs = 200
all_scores = []

for i in range(k):
    print(f'processing {i}-fold ...')
    # k-fold CV에서 사용할 검증(validation) 데이터
    val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples]
    val_targets = Y_train[i * num_val_samples : (i + 1) * num_val_samples]
    
    # k-fold CV에서 사용할 학습(train) 데이터:
    # 원래 학습 데이터에서 검증 데이터를 제외한 나머지
    part_train_data = np.concatenate(
        [train_data[:i * num_val_samples],
         train_data[(i + 1) * num_val_samples:]],
        axis=0)
    part_train_targets = np.concatenate(
        [Y_train[:i * num_val_samples],
         Y_train[(i + 1) * num_val_samples:]],
        axis=0)
    
    # 모델 생성 & 컴파일
    model = build_model()
    
    # 모델 학습
    fitted = model.fit(part_train_data, part_train_targets,
              epochs=num_epochs, verbose=0)
    loss = fitted.history['loss']
    all_scores.append(loss)

# K-Fold 모델 성능 시각화
all_scores = np.array(all_scores)
print(all_scores)

average_scores = all_scores.mean(axis=0)
plt.plot(average_scores)
plt.show()

# 모델 평가
eval = model.evaluate(test_data, Y_test)
print(eval)